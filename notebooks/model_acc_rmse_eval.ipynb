{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin c:\\Users\\Abstract\\mambaforge\\envs\\sentenv2\\lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda121.dll\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ElectraForSequenceClassification(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 1024)\n",
       "      (token_type_embeddings): Embedding(2, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): ElectraClassificationHead(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=1024, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from transformers import DataCollatorWithPadding, AutoTokenizer\n",
    "from transformers import AutoModel, ElectraForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/electra-large-discriminator\")\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "electra = ElectraForSequenceClassification.from_pretrained(\"AbstractQbit/electra_large_imdb_htsplice\") #(\"my_awesome_electra_large_spliced/checkpoint-1562\")\n",
    "electra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9.9518, 9.9582, 6.4365, 1.0593])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    inp = tokenizer([\"I enjoyed this movie.\", \"this was an absolute blast!\", \"This was a fine movie, but I wouldn't watch it again to be honest, a bit too drawn out for my liking. My friends liked it though, so if you like detectives, you may want to watch it, if you have some spare time.\", \"This was an absolutely horrible movie!\"], return_tensors=\"pt\", padding=True)\n",
    "    print(1 + 9*F.softmax(electra(**inp).logits, dim=-1)[...,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['text', 'label'],\n",
       "         num_rows: 25000\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['text', 'label'],\n",
       "         num_rows: 25000\n",
       "     })\n",
       " }),\n",
       " {'text': 'I love sci-fi and am willing to put up with a lot. Sci-fi movies/TV are usually underfunded, under-appreciated and misunderstood. I tried to like this, I really did, but it is to good TV sci-fi as Babylon 5 is to Star Trek (the original). Silly prosthetics, cheap cardboard sets, stilted dialogues, CG that doesn\\'t match the background, and painfully one-dimensional characters cannot be overcome with a \\'sci-fi\\' setting. (I\\'m sure there are those of you out there who think Babylon 5 is good sci-fi TV. It\\'s not. It\\'s clich√©d and uninspiring.) While US viewers might like emotion and character development, sci-fi is a genre that does not take itself seriously (cf. Star Trek). It may treat important issues, yet not as a serious philosophy. It\\'s really difficult to care about the characters here as they are not simply foolish, just missing a spark of life. Their actions and reactions are wooden and predictable, often painful to watch. The makers of Earth KNOW it\\'s rubbish as they have to always say \"Gene Roddenberry\\'s Earth...\" otherwise people would not continue watching. Roddenberry\\'s ashes must be turning in their orbit as this dull, cheap, poorly edited (watching it without advert breaks really brings this home) trudging Trabant of a show lumbers into space. Spoiler. So, kill off a main character. And then bring him back as another actor. Jeeez! Dallas all over again.',\n",
       "  'label': 3.0},\n",
       " {'text': \"Previous reviewer Claudio Carvalho gave a much better recap of the film's plot details than I could. What I recall mostly is that it was just so beautiful, in every sense - emotionally, visually, editorially - just gorgeous.<br /><br />If you like movies that are wonderful to look at, and also have emotional content to which that beauty is relevant, I think you will be glad to have seen this extraordinary and unusual work of art.<br /><br />On a scale of 1 to 10, I'd give it about an 8.75. The only reason I shy away from 9 is that it is a mood piece. If you are in the mood for a really artistic, very romantic film, then it's a 10. I definitely think it's a must-see, but none of us can be in that mood all the time, so, overall, 8.75.\",\n",
       "  'label': 10.0})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "imdb = load_dataset(\"./imdb_reg.py\")\n",
    "imdb.pop(\"unsupervised\")\n",
    "imdb, imdb[\"test\"][0], imdb[\"test\"][12500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tokenize_with_splicing(examples):\n",
    "    tokens = tokenizer(examples[\"text\"], truncation=False)\n",
    "    if type(tokens['input_ids'][0]) == list:\n",
    "        for i in range(len(tokens['input_ids'])):\n",
    "            if len(tokens['input_ids'][i]) > 512:\n",
    "                tokens['input_ids'][i] = tokens['input_ids'][i][:129] + \\\n",
    "                    [102] + tokens['input_ids'][i][-382:]\n",
    "                tokens['token_type_ids'][i] = [0]*512\n",
    "                tokens['attention_mask'][i] = [1]*512\n",
    "    elif len(tokens['input_ids']) > 512:\n",
    "        tokens['input_ids'] = tokens['input_ids'][:129] + \\\n",
    "            [102] + tokens['input_ids'][-382:]\n",
    "        tokens['token_type_ids'] = [0]*512\n",
    "        tokens['attention_mask'] = [1]*512\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_imdb = imdb.map(preprocess_tokenize_with_splicing, batched=True)\n",
    "tokenized_imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "electra.to('cuda');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_with_electra(examples):\n",
    "    # print(type(examples))\n",
    "    batch = data_collator({'input_ids':examples['input_ids'],\n",
    "                'token_type_ids':examples['token_type_ids'],\n",
    "                'attention_mask':examples['attention_mask']}).to('cuda')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        conf_based_rating = 1 + 9*F.softmax(electra(**batch).logits, dim=-1)[...,1]\n",
    "    return {\"predicted\": conf_based_rating.to('cpu')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e2e20fb17cc49f3aca82c64e90ec806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a ElectraTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57ca02b7d6e24de9b552205d4c77e0d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask', 'predicted'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask', 'predicted'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_with_predicts = tokenized_imdb.map(pred_with_electra, batch_size=256, batched=True)\n",
    "imdb_with_predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acfbd9dbefc44294b74501b0c0d71857",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c8c86c01cc14e3f9501366377a66b39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imdb_with_predicts.save_to_disk('./imdb_with_predicts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3., 4., 3., ..., 7., 9., 7.]),\n",
       " array([1.01970351, 1.88304043, 1.0522753 , ..., 9.85711288, 9.97132874,\n",
       "        9.75077724]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(imdb_with_predicts['test']['label']), np.array(imdb_with_predicts['test']['predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9215112316539822"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.array(imdb_with_predicts['test']['predicted'])\n",
    "ratings = np.array(imdb_with_predicts['test']['label'])\n",
    "np.mean((predictions - ratings)**2)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.9215112316539822, 0.96628)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "\n",
    "mean_squared_error(ratings, predictions, squared=False), accuracy_score(ratings>5.5, predictions>5.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "del electra\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "electra_reg = ElectraForSequenceClassification.from_pretrained(\"AbstractQbit/electra_large_imdb_regression_htsplice\") #(\"./electra_large_imdb_reg_spliced_fix10/checkpoint-2343\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_with_electra_reg(examples):\n",
    "    batch = data_collator({'input_ids':examples['input_ids'],\n",
    "                'token_type_ids':examples['token_type_ids'],\n",
    "                'attention_mask':examples['attention_mask']}).to('cuda')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        reg_rating = electra_reg(**batch).logits[...,0]\n",
    "    return {\"predicted_reg\": reg_rating.to('cpu')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "electra_reg.to('cuda');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dc09767c1aa4fc18a9d58ad06c47e9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab2518a1e1df4c69bb7facb72d35bae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask', 'predicted', 'predicted_reg'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask', 'predicted', 'predicted_reg'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_with_predicts2 = imdb_with_predicts.map(pred_with_electra_reg, batch_size=256, batched=True)\n",
    "imdb_with_predicts2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a65dddc97d7b4c7a8a1785414cb64404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aea2f04c29bf4ae3a2f93eed7f633566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imdb_with_predicts2.save_to_disk('./imdb_with_predicts2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import load_from_disk\n",
    "# imdb_with_predicts2 = load_from_disk('./imdb_with_predicts2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "\n",
    "def print_metrics(label, target, pred):\n",
    "    print(label)\n",
    "    print(f'Rating RMSE: {mean_squared_error(target, pred, squared=False):0.3f}')\n",
    "    print(f'Polarity accuracy: {accuracy_score(target>5.5, pred>5.5):0.3f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Test split:\n",
      "ELECTRA tuned with polarity:\n",
      "Rating RMSE: 1.922\n",
      "Polarity accuracy: 0.966\n",
      "\n",
      "ELECTRA tuned with regression:\n",
      "Rating RMSE: 1.318\n",
      "Polarity accuracy: 0.964\n",
      "\n",
      "\n",
      "On Train split:\n",
      "ELECTRA tuned with polarity:\n",
      "Rating RMSE: 1.790\n",
      "Polarity accuracy: 0.987\n",
      "\n",
      "ELECTRA tuned with regression:\n",
      "Rating RMSE: 1.070\n",
      "Polarity accuracy: 0.983\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('On Test split:')\n",
    "ratings = np.array(imdb_with_predicts2['test']['label'])\n",
    "predictions_cls = np.array(imdb_with_predicts2['test']['predicted'])\n",
    "predictions_reg = np.array(imdb_with_predicts2['test']['predicted_reg'])\n",
    "print_metrics('ELECTRA tuned with polarity:', ratings, predictions_cls)\n",
    "print_metrics('ELECTRA tuned with regression:', ratings, predictions_reg)\n",
    "\n",
    "print('\\nOn Train split:')\n",
    "ratings = np.array(imdb_with_predicts2['train']['label'])\n",
    "predictions_cls = np.array(imdb_with_predicts2['train']['predicted'])\n",
    "predictions_reg = np.array(imdb_with_predicts2['train']['predicted_reg'])\n",
    "print_metrics('ELECTRA tuned with polarity:', ratings, predictions_cls)\n",
    "print_metrics('ELECTRA tuned with regression:', ratings, predictions_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratings = np.array(imdb_with_predicts2['test']['label'])\n",
    "# predictions_cls = np.array(imdb_with_predicts2['test']['predicted'])\n",
    "# predictions_reg = np.array(imdb_with_predicts2['test']['predicted_reg'])\n",
    "# ratings, predictions_cls, predictions_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'ELECTRA tuned with polarity:\\nRating RMSE: {mean_squared_error(ratings, predictions_cls, squared=False):0.3f}\\nPolarity accuracy: {accuracy_score(ratings>5.5, predictions_cls>5.5):0.3f}\\n')\n",
    "# print(f'ELECTRA tuned with regression:\\nRating RMSE: {mean_squared_error(ratings, predictions_reg, squared=False):0.3f}\\nPolarity accuracy: {accuracy_score(ratings>5.5, predictions_reg>5.5):0.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentenv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
